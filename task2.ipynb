
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Machine learning libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_curve,
    auc,
    precision_recall_curve
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import SMOTE

# ------------------------------
# 1. Load Dataset
# ------------------------------
data_path = r"F:\elevvo\loan_approval_dataset.csv"   # <-- your dataset path
df = pd.read_csv(data_path)

# Fix: strip leading/trailing spaces in column names
df.columns = df.columns.str.strip()

print("Initial shape of dataset:", df.shape)
print("Available columns:", df.columns.tolist())
print(df.head())

# ------------------------------
# 2. Handle Missing Values
# ------------------------------
for col in df.select_dtypes(include=np.number).columns:
    df[col] = df[col].fillna(df[col].median())

for col in df.select_dtypes(include="object").columns:
    df[col] = df[col].fillna(df[col].mode()[0])

# ------------------------------
# 3. Encode Categorical Features
# ------------------------------
le = LabelEncoder()
for col in df.select_dtypes(include="object").columns:
    df[col] = le.fit_transform(df[col])

# ------------------------------
# 4. Define Features & Target
# ------------------------------
target_col = "loan_status"   # <-- set manually
X = df.drop([target_col, "loan_id"], axis=1)
y = df[target_col]

# ------------------------------
# 5. Handle Imbalanced Data
# ------------------------------
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("After SMOTE:", X_resampled.shape, y_resampled.value_counts())

# ------------------------------
# 6. Train-Test Split
# ------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled
)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ------------------------------
# 7. Train Multiple Models
# ------------------------------
models = {
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42, class_weight="balanced"),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42, class_weight="balanced"),
    "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight="balanced")
}

results = {}

for name, model in models.items():
    print(f"\n=== Training {name} ===")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Store metrics
    results[name] = {
        "y_pred": y_pred,
        "y_prob": model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
    }

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, digits=4))

# ------------------------------
# 8. Visualizations
# ------------------------------

# Confusion matrices
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
for ax, (name, res) in zip(axes, results.items()):
    cm = confusion_matrix(y_test, res["y_pred"])
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_title(f"{name} - Confusion Matrix")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
plt.tight_layout()
plt.show()

# ROC curves
plt.figure(figsize=(8,6))
for name, res in results.items():
    if res["y_prob"] is not None:
        fpr, tpr, _ = roc_curve(y_test, res["y_prob"])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"{name} (AUC={roc_auc:.3f})")
plt.plot([0,1], [0,1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves")
plt.legend()
plt.show()

# Precision-Recall curves
plt.figure(figsize=(8,6))
for name, res in results.items():
    if res["y_prob"] is not None:
        precision, recall, _ = precision_recall_curve(y_test, res["y_prob"])
        plt.plot(recall, precision, label=name)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curves")
plt.legend()
plt.show()

# Feature Importance (only for Random Forest & Decision Tree)
for name, model in models.items():
    if hasattr(model, "feature_importances_"):
        importances = model.feature_importances_
        feat_imp = pd.Series(importances, index=df.drop([target_col, "loan_id"], axis=1).columns)
        feat_imp.sort_values(ascending=False).head(15).plot(kind="bar", figsize=(10,5))
        plt.title(f"{name} - Top 15 Feature Importances")
        plt.show()

